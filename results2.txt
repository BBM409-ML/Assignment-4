
------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 16, Learning Rate: 0.005, Epoch: 1
Loss Value: 2.44%
Train Accuracy: 23.82%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 16, Learning Rate: 0.005, Epoch: 2
Loss Value: 2.31%
Train Accuracy: 26.89%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 16, Learning Rate: 0.005, Epoch: 3
Loss Value: 2.24%
Train Accuracy: 28.88%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 16, Learning Rate: 0.005, Epoch: 4
Loss Value: 2.18%
Train Accuracy: 30.23%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 16, Learning Rate: 0.005, Epoch: 5
Loss Value: 2.14%
Train Accuracy: 31.48%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 16, Learning Rate: 0.005, Epoch: 6
Loss Value: 2.11%
Train Accuracy: 32.35%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 16, Learning Rate: 0.005, Epoch: 7
Loss Value: 2.08%
Train Accuracy: 33.25%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 16, Learning Rate: 0.005, Epoch: 8
Loss Value: 2.06%
Train Accuracy: 34.03%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 16, Learning Rate: 0.005, Epoch: 9
Loss Value: 2.03%
Train Accuracy: 34.74%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 16, Learning Rate: 0.005, Epoch: 10
Loss Value: 2.01%
Train Accuracy: 35.24%
Accuracy: 31.90%
Confusion matrix:
[[147.  31.  10.  63.  34.  11.  13.  23. 123.  17.]
 [ 39. 103.   4.  25.  20.   5.   9.  12.  45.   5.]
 [ 27.  15.  21.  15.   9.   2.   7.   1.  28.   3.]
 [ 47.  13.   2.  77.  14.   7.  12.   4.  28.   4.]
 [ 56.  23.   7.  32. 101.   6.  10.  15.  54.   6.]
 [ 28.  11.   3.  27.  16.  19.   4.  10.  34.   5.]
 [ 41.  17.   5.  10.  14.   4.  36.  15.  36.   4.]
 [ 43.  11.   0.  15.  12.   8.  10.  57.  39.   4.]
 [ 80.  30.   6.  53.  45.   4.  13.  12. 231.  11.]
 [ 46.  16.   3.  18.  20.   7.   8.  10.  32.  40.]]
*******************************************

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 16, Learning Rate: 0.01, Epoch: 1
Loss Value: 3.06%
Train Accuracy: 18.64%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 16, Learning Rate: 0.01, Epoch: 2
Loss Value: 2.88%
Train Accuracy: 21.84%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 16, Learning Rate: 0.01, Epoch: 3
Loss Value: 2.77%
Train Accuracy: 24.38%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 16, Learning Rate: 0.01, Epoch: 4
Loss Value: 2.69%
Train Accuracy: 26.04%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 16, Learning Rate: 0.01, Epoch: 5
Loss Value: 2.63%
Train Accuracy: 27.25%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 16, Learning Rate: 0.01, Epoch: 6
Loss Value: 2.58%
Train Accuracy: 28.04%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 16, Learning Rate: 0.01, Epoch: 7
Loss Value: 2.53%
Train Accuracy: 28.68%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 16, Learning Rate: 0.01, Epoch: 8
Loss Value: 2.49%
Train Accuracy: 29.54%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 16, Learning Rate: 0.01, Epoch: 9
Loss Value: 2.46%
Train Accuracy: 30.45%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 16, Learning Rate: 0.01, Epoch: 10
Loss Value: 2.43%
Train Accuracy: 31.33%
Accuracy: 28.49%
Confusion matrix:
[[107.  49.  16.  87.  30.  21.  15.  15. 111.  21.]
 [ 35.  94.   8.  41.  11.   5.   9.  10.  46.   8.]
 [ 16.  13.  24.  27.   6.   3.   5.   3.  27.   4.]
 [ 28.  27.   7.  81.   9.   6.  12.   4.  26.   8.]
 [ 52.  30.   9.  47.  81.   5.  10.  19.  48.   9.]
 [ 21.  15.   3.  41.   9.  21.   4.   4.  32.   7.]
 [ 27.  26.   7.  16.  10.   7.  28.  18.  33.  10.]
 [ 40.  16.   2.  21.   9.   6.   7.  57.  36.   5.]
 [ 45.  63.  12.  78.  34.   8.  12.  12. 202.  19.]
 [ 24.  28.   7.  23.  18.   5.   8.  11.  28.  48.]]
*******************************************

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 16, Learning Rate: 0.02, Epoch: 1
Loss Value: 4.99%
Train Accuracy: 15.85%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 16, Learning Rate: 0.02, Epoch: 2
Loss Value: 4.67%
Train Accuracy: 20.08%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 16, Learning Rate: 0.02, Epoch: 3
Loss Value: 4.44%
Train Accuracy: 23.32%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 16, Learning Rate: 0.02, Epoch: 4
Loss Value: 4.30%
Train Accuracy: 23.90%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 16, Learning Rate: 0.02, Epoch: 5
Loss Value: 4.21%
Train Accuracy: 25.82%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 16, Learning Rate: 0.02, Epoch: 6
Loss Value: 4.10%
Train Accuracy: 25.15%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 16, Learning Rate: 0.02, Epoch: 7
Loss Value: 4.02%
Train Accuracy: 26.33%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 16, Learning Rate: 0.02, Epoch: 8
Loss Value: 3.96%
Train Accuracy: 27.71%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 16, Learning Rate: 0.02, Epoch: 9
Loss Value: 3.88%
Train Accuracy: 27.39%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 16, Learning Rate: 0.02, Epoch: 10
Loss Value: 3.84%
Train Accuracy: 26.11%
Accuracy: 23.08%
Confusion matrix:
[[ 93.  32.  27. 132.  30.  19.  18.  19.  62.  40.]
 [ 30.  93.  12.  58.  11.   7.   7.   8.  26.  15.]
 [ 13.  11.  17.  38.   6.   2.   5.   6.  19.  11.]
 [ 27.  15.   8.  89.   8.   6.  10.   4.  13.  28.]
 [ 42.  24.  14.  72.  60.   9.  10.  21.  27.  31.]
 [ 17.   6.   6.  51.   5.  23.   8.   2.  18.  21.]
 [ 22.  22.   9.  28.  12.  13.  30.  15.  18.  13.]
 [ 36.   9.   5.  30.  10.  11.   7.  46.  29.  16.]
 [ 46.  28.  20. 170.  20.  10.  12.  19.  93.  67.]
 [ 26.  12.   7.  37.  14.   7.   5.  10.  24.  58.]]
*******************************************

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 32, Learning Rate: 0.005, Epoch: 1
Loss Value: 2.29%
Train Accuracy: 27.40%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 32, Learning Rate: 0.005, Epoch: 2
Loss Value: 2.19%
Train Accuracy: 29.36%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 32, Learning Rate: 0.005, Epoch: 3
Loss Value: 2.13%
Train Accuracy: 30.67%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 32, Learning Rate: 0.005, Epoch: 4
Loss Value: 2.09%
Train Accuracy: 31.81%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 32, Learning Rate: 0.005, Epoch: 5
Loss Value: 2.06%
Train Accuracy: 32.63%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 32, Learning Rate: 0.005, Epoch: 6
Loss Value: 2.03%
Train Accuracy: 33.29%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 32, Learning Rate: 0.005, Epoch: 7
Loss Value: 2.00%
Train Accuracy: 33.94%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 32, Learning Rate: 0.005, Epoch: 8
Loss Value: 1.98%
Train Accuracy: 34.65%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 32, Learning Rate: 0.005, Epoch: 9
Loss Value: 1.97%
Train Accuracy: 35.21%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 32, Learning Rate: 0.005, Epoch: 10
Loss Value: 1.95%
Train Accuracy: 35.63%
Accuracy: 33.14%
Confusion matrix:
[[171.  25.   4.  24.  39.  11.  13.  25. 148.  11.]
 [ 52.  97.   4.  10.  25.   3.  14.  12.  45.   3.]
 [ 36.  16.  14.   7.  14.   0.   8.   1.  30.   1.]
 [ 48.  11.   2.  57.  18.  10.  11.   6.  41.   0.]
 [ 64.  20.   4.  13. 109.   5.  10.  18.  60.   5.]
 [ 40.   7.   1.  12.  19.  17.   4.  10.  42.   3.]
 [ 43.  18.   2.   5.  18.   2.  42.  13.  35.   4.]
 [ 46.  15.   0.   7.  14.   3.  15.  56.  41.   1.]
 [ 84.  22.   5.  14.  58.   1.  12.  11. 271.   5.]
 [ 54.  14.   3.   7.  26.   8.  11.   8.  43.  25.]]
*******************************************

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 32, Learning Rate: 0.01, Epoch: 1
Loss Value: 2.58%
Train Accuracy: 25.76%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 32, Learning Rate: 0.01, Epoch: 2
Loss Value: 2.45%
Train Accuracy: 27.90%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 32, Learning Rate: 0.01, Epoch: 3
Loss Value: 2.38%
Train Accuracy: 29.56%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 32, Learning Rate: 0.01, Epoch: 4
Loss Value: 2.33%
Train Accuracy: 30.76%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 32, Learning Rate: 0.01, Epoch: 5
Loss Value: 2.28%
Train Accuracy: 31.75%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 32, Learning Rate: 0.01, Epoch: 6
Loss Value: 2.24%
Train Accuracy: 32.50%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 32, Learning Rate: 0.01, Epoch: 7
Loss Value: 2.21%
Train Accuracy: 33.14%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 32, Learning Rate: 0.01, Epoch: 8
Loss Value: 2.18%
Train Accuracy: 33.82%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 32, Learning Rate: 0.01, Epoch: 9
Loss Value: 2.15%
Train Accuracy: 34.36%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 32, Learning Rate: 0.01, Epoch: 10
Loss Value: 2.13%
Train Accuracy: 34.97%
Accuracy: 31.79%
Confusion matrix:
[[128.  28.   8.  38.  40.  13.  20.  19. 163.  14.]
 [ 41.  95.   3.  19.  20.   5.  12.   8.  55.   7.]
 [ 25.  10.  19.  10.  11.   1.   7.   3.  37.   4.]
 [ 35.  14.   2.  60.  20.   9.  11.   4.  44.   5.]
 [ 54.  20.   6.  19. 105.   4.   8.  18.  67.   7.]
 [ 20.   6.   1.  18.  20.  21.   8.  10.  45.   6.]
 [ 35.  18.   6.   7.  19.   5.  31.  16.  36.   9.]
 [ 35.   8.   1.  15.  13.   4.  13.  62.  42.   5.]
 [ 57.  24.   5.  20.  60.   6.  20.  10. 267.  14.]
 [ 32.  18.   2.  14.  23.   8.  11.  10.  45.  36.]]
*******************************************

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 32, Learning Rate: 0.02, Epoch: 1
Loss Value: 3.74%
Train Accuracy: 22.15%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 32, Learning Rate: 0.02, Epoch: 2
Loss Value: 3.54%
Train Accuracy: 24.23%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 32, Learning Rate: 0.02, Epoch: 3
Loss Value: 3.41%
Train Accuracy: 26.14%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 32, Learning Rate: 0.02, Epoch: 4
Loss Value: 3.32%
Train Accuracy: 27.82%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 32, Learning Rate: 0.02, Epoch: 5
Loss Value: 3.24%
Train Accuracy: 28.90%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 32, Learning Rate: 0.02, Epoch: 6
Loss Value: 3.15%
Train Accuracy: 29.95%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 32, Learning Rate: 0.02, Epoch: 7
Loss Value: 3.10%
Train Accuracy: 30.67%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 32, Learning Rate: 0.02, Epoch: 8
Loss Value: 3.05%
Train Accuracy: 31.39%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 32, Learning Rate: 0.02, Epoch: 9
Loss Value: 3.00%
Train Accuracy: 31.86%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 32, Learning Rate: 0.02, Epoch: 10
Loss Value: 2.95%
Train Accuracy: 32.30%
Accuracy: 29.63%
Confusion matrix:
[[ 88.  19.  11.  41.  28.  20.  23.  22. 161.  58.]
 [ 27.  85.   7.  28.  10.   7.   7.  11.  50.  33.]
 [ 15.   9.  22.  17.   6.   3.   4.   2.  36.  13.]
 [ 19.   8.   5.  63.  15.   5.  10.   5.  43.  31.]
 [ 48.  21.   7.  32.  74.   3.   5.  18.  62.  38.]
 [ 11.   6.   1.  13.   8.  19.  11.   6.  53.  27.]
 [ 30.  14.   7.  11.  15.   4.  27.  16.  33.  25.]
 [ 24.   8.   1.  18.   9.   6.   8.  57.  40.  27.]
 [ 36.  13.  11.  26.  31.   3.   9.   8. 257.  89.]
 [ 19.   8.   4.  15.  10.   5.   5.  11.  46.  76.]]
*******************************************

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 64, Learning Rate: 0.005, Epoch: 1
Loss Value: 2.24%
Train Accuracy: 26.51%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 64, Learning Rate: 0.005, Epoch: 2
Loss Value: 2.16%
Train Accuracy: 28.31%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 64, Learning Rate: 0.005, Epoch: 3
Loss Value: 2.12%
Train Accuracy: 29.54%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 64, Learning Rate: 0.005, Epoch: 4
Loss Value: 2.08%
Train Accuracy: 30.46%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 64, Learning Rate: 0.005, Epoch: 5
Loss Value: 2.05%
Train Accuracy: 31.33%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 64, Learning Rate: 0.005, Epoch: 6
Loss Value: 2.03%
Train Accuracy: 32.24%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 64, Learning Rate: 0.005, Epoch: 7
Loss Value: 2.01%
Train Accuracy: 32.77%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 64, Learning Rate: 0.005, Epoch: 8
Loss Value: 1.99%
Train Accuracy: 33.36%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 64, Learning Rate: 0.005, Epoch: 9
Loss Value: 1.98%
Train Accuracy: 33.83%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 64, Learning Rate: 0.005, Epoch: 10
Loss Value: 1.96%
Train Accuracy: 34.25%
Accuracy: 31.56%
Confusion matrix:
[[164.  28.   3.  14.  42.  13.  16.  28. 148.   9.]
 [ 43.  99.   0.   5.  25.   2.  21.  14.  52.   1.]
 [ 28.  18.  10.   3.  14.   0.  12.   4.  35.   1.]
 [ 52.  12.   2.  35.  21.   9.   7.   8.  54.   0.]
 [ 59.  23.   2.   6. 101.   6.  14.  23.  64.   5.]
 [ 38.   6.   0.   4.  20.  11.   6.  16.  49.   4.]
 [ 33.  18.   1.   2.  25.   1.  44.  15.  37.   5.]
 [ 46.  17.   1.   5.   9.   2.  16.  53.  46.   2.]
 [ 69.  20.   5.  10.  63.   3.  11.  17. 274.   6.]
 [ 47.  15.   2.   9.  28.   5.  14.   7.  51.  17.]]
*******************************************

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 64, Learning Rate: 0.01, Epoch: 1
Loss Value: 2.38%
Train Accuracy: 27.69%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 64, Learning Rate: 0.01, Epoch: 2
Loss Value: 2.28%
Train Accuracy: 29.08%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 64, Learning Rate: 0.01, Epoch: 3
Loss Value: 2.23%
Train Accuracy: 29.82%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 64, Learning Rate: 0.01, Epoch: 4
Loss Value: 2.19%
Train Accuracy: 30.45%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 64, Learning Rate: 0.01, Epoch: 5
Loss Value: 2.15%
Train Accuracy: 31.10%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 64, Learning Rate: 0.01, Epoch: 6
Loss Value: 2.13%
Train Accuracy: 31.64%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 64, Learning Rate: 0.01, Epoch: 7
Loss Value: 2.10%
Train Accuracy: 32.08%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 64, Learning Rate: 0.01, Epoch: 8
Loss Value: 2.08%
Train Accuracy: 32.58%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 64, Learning Rate: 0.01, Epoch: 9
Loss Value: 2.06%
Train Accuracy: 33.09%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 64, Learning Rate: 0.01, Epoch: 10
Loss Value: 2.04%
Train Accuracy: 33.61%
Accuracy: 31.76%
Confusion matrix:
[[153.  27.   2.   9.  31.   3.   9.  22. 196.  13.]
 [ 50.  98.   1.   6.  19.   1.  15.   9.  60.   3.]
 [ 30.  15.  11.   4.  12.   0.   7.   2.  41.   3.]
 [ 64.   9.   2.  34.  11.   5.   9.   6.  59.   1.]
 [ 56.  25.   1.  10. 102.   4.   7.  18.  76.   4.]
 [ 33.   8.   0.   4.  12.  12.   6.  11.  63.   5.]
 [ 35.  16.   1.   3.  18.   2.  42.  14.  44.   6.]
 [ 43.  14.   0.   5.  10.   2.  11.  53.  58.   1.]
 [117.  15.   2.   6.  28.   1.  15.  10. 282.   2.]
 [ 56.  15.   1.   8.  17.   3.   9.   7.  53.  26.]]
*******************************************

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 64, Learning Rate: 0.02, Epoch: 1
Loss Value: 3.22%
Train Accuracy: 25.56%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 64, Learning Rate: 0.02, Epoch: 2
Loss Value: 3.09%
Train Accuracy: 26.80%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 64, Learning Rate: 0.02, Epoch: 3
Loss Value: 2.98%
Train Accuracy: 27.56%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 64, Learning Rate: 0.02, Epoch: 4
Loss Value: 2.92%
Train Accuracy: 28.12%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 64, Learning Rate: 0.02, Epoch: 5
Loss Value: 2.85%
Train Accuracy: 28.80%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 64, Learning Rate: 0.02, Epoch: 6
Loss Value: 2.80%
Train Accuracy: 29.24%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 64, Learning Rate: 0.02, Epoch: 7
Loss Value: 2.76%
Train Accuracy: 29.86%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 64, Learning Rate: 0.02, Epoch: 8
Loss Value: 2.73%
Train Accuracy: 30.26%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 64, Learning Rate: 0.02, Epoch: 9
Loss Value: 2.70%
Train Accuracy: 31.00%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 64, Learning Rate: 0.02, Epoch: 10
Loss Value: 2.66%
Train Accuracy: 31.96%
Accuracy: 29.77%
Confusion matrix:
[[138.  30.   9.  14.  25.   6.  11.  19. 191.  22.]
 [ 55.  94.   5.   6.  17.   4.   9.   9.  56.   7.]
 [ 33.   9.  15.   4.   9.   1.   3.   1.  43.   7.]
 [ 68.   6.   2.  32.   7.   4.   5.   4.  69.   3.]
 [ 66.  25.   3.   9.  92.   5.   6.  16.  77.   4.]
 [ 44.   6.   2.   4.   8.   9.   3.   5.  66.   7.]
 [ 45.  17.   4.   2.  13.   4.  30.  13.  46.   7.]
 [ 41.  13.   1.   9.  10.   4.   8.  53.  56.   2.]
 [148.  11.   5.   6.  14.   3.   8.   6. 270.   7.]
 [ 70.  13.   1.   6.   9.   2.   7.   6.  52.  29.]]
*******************************************

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 128, Learning Rate: 0.005, Epoch: 1
Loss Value: 2.22%
Train Accuracy: 24.92%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 128, Learning Rate: 0.005, Epoch: 2
Loss Value: 2.16%
Train Accuracy: 26.27%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 128, Learning Rate: 0.005, Epoch: 3
Loss Value: 2.13%
Train Accuracy: 27.08%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 128, Learning Rate: 0.005, Epoch: 4
Loss Value: 2.10%
Train Accuracy: 27.82%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 128, Learning Rate: 0.005, Epoch: 5
Loss Value: 2.08%
Train Accuracy: 28.55%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 128, Learning Rate: 0.005, Epoch: 6
Loss Value: 2.06%
Train Accuracy: 29.10%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 128, Learning Rate: 0.005, Epoch: 7
Loss Value: 2.04%
Train Accuracy: 29.57%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 128, Learning Rate: 0.005, Epoch: 8
Loss Value: 2.03%
Train Accuracy: 30.10%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 128, Learning Rate: 0.005, Epoch: 9
Loss Value: 2.02%
Train Accuracy: 30.57%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 128, Learning Rate: 0.005, Epoch: 10
Loss Value: 2.00%
Train Accuracy: 30.96%
Accuracy: 29.14%
Confusion matrix:
[[116.  34.   6.  16.  43.   7.  14.  36. 180.  13.]
 [ 39. 100.   1.   1.  24.   3.  19.  14.  58.   3.]
 [ 22.  19.   9.   3.  14.   1.  11.   4.  40.   2.]
 [ 41.  11.   7.  32.  16.   4.   4.  12.  68.   5.]
 [ 54.  25.   5.   6.  96.   6.  12.  22.  70.   7.]
 [ 33.  11.   2.   5.  16.   5.   7.  17.  51.   7.]
 [ 30.  22.   1.   2.  23.   1.  42.  21.  35.   4.]
 [ 38.  14.   0.   6.  12.   3.  14.  55.  50.   5.]
 [ 57.  21.   7.   8.  67.   5.  15.  16. 271.  11.]
 [ 41.  17.   0.   6.  35.   5.  11.   8.  52.  20.]]
*******************************************

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 128, Learning Rate: 0.01, Epoch: 1
Loss Value: 2.29%
Train Accuracy: 26.64%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 128, Learning Rate: 0.01, Epoch: 2
Loss Value: 2.21%
Train Accuracy: 28.20%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 128, Learning Rate: 0.01, Epoch: 3
Loss Value: 2.17%
Train Accuracy: 29.26%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 128, Learning Rate: 0.01, Epoch: 4
Loss Value: 2.13%
Train Accuracy: 30.26%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 128, Learning Rate: 0.01, Epoch: 5
Loss Value: 2.11%
Train Accuracy: 31.01%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 128, Learning Rate: 0.01, Epoch: 6
Loss Value: 2.09%
Train Accuracy: 31.65%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 128, Learning Rate: 0.01, Epoch: 7
Loss Value: 2.07%
Train Accuracy: 32.20%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 128, Learning Rate: 0.01, Epoch: 8
Loss Value: 2.06%
Train Accuracy: 32.83%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 128, Learning Rate: 0.01, Epoch: 9
Loss Value: 2.04%
Train Accuracy: 33.35%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 128, Learning Rate: 0.01, Epoch: 10
Loss Value: 2.03%
Train Accuracy: 33.78%
Accuracy: 31.13%
Confusion matrix:
[[164.  26.   5.  20.  48.  16.  16.  34. 125.  11.]
 [ 50.  96.   1.   7.  21.   2.  23.  14.  46.   2.]
 [ 27.  12.  10.   5.  18.   0.  16.   3.  31.   3.]
 [ 43.  10.   6.  42.  23.  13.   8.  12.  42.   1.]
 [ 65.  27.   4.   9.  98.   9.  11.  21.  55.   4.]
 [ 46.   7.   0.   7.  23.  12.   3.  12.  41.   3.]
 [ 31.  18.   3.   3.  22.   4.  47.  17.  31.   5.]
 [ 44.  16.   1.   6.  11.   5.  17.  57.  39.   1.]
 [ 82.  19.   5.   8.  72.   5.  15.  15. 253.   4.]
 [ 52.  14.   3.  10.  30.   6.  11.   7.  44.  18.]]
*******************************************

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 128, Learning Rate: 0.02, Epoch: 1
Loss Value: 2.95%
Train Accuracy: 24.14%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 128, Learning Rate: 0.02, Epoch: 2
Loss Value: 2.91%
Train Accuracy: 24.95%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 128, Learning Rate: 0.02, Epoch: 3
Loss Value: 2.81%
Train Accuracy: 25.73%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 128, Learning Rate: 0.02, Epoch: 4
Loss Value: 2.77%
Train Accuracy: 26.44%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 128, Learning Rate: 0.02, Epoch: 5
Loss Value: 2.72%
Train Accuracy: 25.00%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 128, Learning Rate: 0.02, Epoch: 6
Loss Value: 2.70%
Train Accuracy: 27.67%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 128, Learning Rate: 0.02, Epoch: 7
Loss Value: 2.66%
Train Accuracy: 27.96%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 128, Learning Rate: 0.02, Epoch: 8
Loss Value: 2.61%
Train Accuracy: 28.67%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 128, Learning Rate: 0.02, Epoch: 9
Loss Value: 2.59%
Train Accuracy: 29.04%

------------------------------------------------------------
Neurons: [4096, 10], Batch Size: 128, Learning Rate: 0.02, Epoch: 10
Loss Value: 2.59%
Train Accuracy: 28.67%
Accuracy: 26.41%
Confusion matrix:
[[127.  25.   5.   6.  20.   5.  12.  18. 231.  16.]
 [ 49.  66.   3.   7.  11.   2.  10.   6. 103.   5.]
 [ 28.   7.   7.   6.   4.   1.   9.   2.  59.   2.]
 [ 64.   7.   3.  22.   7.   5.   5.   4.  83.   0.]
 [ 66.  19.   4.   9.  63.   5.   7.  12. 116.   2.]
 [ 38.   4.   0.   3.  11.   9.   3.   3.  80.   3.]
 [ 39.  11.   3.   2.  12.   1.  38.   9.  61.   5.]
 [ 41.   9.   1.   9.  13.   2.  14.  44.  61.   3.]
 [127.  12.   2.   8.  21.   3.  10.   8. 282.   5.]
 [ 61.   8.   3.   8.   9.   3.   7.   6.  72.  18.]]
*******************************************

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 16, Learning Rate: 0.005, Epoch: 1
Loss Value: 2.04%
Train Accuracy: 33.26%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 16, Learning Rate: 0.005, Epoch: 2
Loss Value: 1.91%
Train Accuracy: 36.81%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 16, Learning Rate: 0.005, Epoch: 3
Loss Value: 1.83%
Train Accuracy: 40.09%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 16, Learning Rate: 0.005, Epoch: 4
Loss Value: 1.76%
Train Accuracy: 43.45%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 16, Learning Rate: 0.005, Epoch: 5
Loss Value: 1.68%
Train Accuracy: 46.73%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 16, Learning Rate: 0.005, Epoch: 6
Loss Value: 1.61%
Train Accuracy: 50.13%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 16, Learning Rate: 0.005, Epoch: 7
Loss Value: 1.53%
Train Accuracy: 53.25%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 16, Learning Rate: 0.005, Epoch: 8
Loss Value: 1.46%
Train Accuracy: 56.39%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 16, Learning Rate: 0.005, Epoch: 9
Loss Value: 1.38%
Train Accuracy: 59.40%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 16, Learning Rate: 0.005, Epoch: 10
Loss Value: 1.30%
Train Accuracy: 62.49%
Accuracy: 59.43%
Confusion matrix:
[[316.  13.   6.  10.  20.   5.   3.  17.  76.   6.]
 [ 39. 174.   4.   0.   8.   0.  17.   8.  17.   0.]
 [ 29.   7.  45.   4.   6.   1.   5.   8.  17.   6.]
 [ 25.   5.   1. 115.   7.   3.   2.   4.  43.   3.]
 [ 38.   6.   0.   7. 181.   5.   9.  17.  39.   8.]
 [ 49.   1.   1.   9.   9.  31.   0.   7.  38.  12.]
 [ 26.  18.   5.   1.   7.   1.  95.  14.  10.   5.]
 [ 40.   9.   2.   5.   4.   2.  13. 100.  21.   3.]
 [ 36.   1.   3.   8.   9.   2.   1.  11. 403.  11.]
 [ 20.   4.   2.  14.  13.   6.   3.   7.  41.  90.]]
*******************************************

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 16, Learning Rate: 0.01, Epoch: 1
Loss Value: 2.02%
Train Accuracy: 35.11%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 16, Learning Rate: 0.01, Epoch: 2
Loss Value: 1.87%
Train Accuracy: 39.90%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 16, Learning Rate: 0.01, Epoch: 3
Loss Value: 1.77%
Train Accuracy: 44.12%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 16, Learning Rate: 0.01, Epoch: 4
Loss Value: 1.68%
Train Accuracy: 48.24%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 16, Learning Rate: 0.01, Epoch: 5
Loss Value: 1.58%
Train Accuracy: 51.95%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 16, Learning Rate: 0.01, Epoch: 6
Loss Value: 1.48%
Train Accuracy: 55.52%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 16, Learning Rate: 0.01, Epoch: 7
Loss Value: 1.38%
Train Accuracy: 59.07%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 16, Learning Rate: 0.01, Epoch: 8
Loss Value: 1.28%
Train Accuracy: 62.43%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 16, Learning Rate: 0.01, Epoch: 9
Loss Value: 1.17%
Train Accuracy: 65.27%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 16, Learning Rate: 0.01, Epoch: 10
Loss Value: 1.07%
Train Accuracy: 67.98%
Accuracy: 64.92%
Confusion matrix:
[[346.   6.   7.   9.   9.   6.   5.  11.  63.  10.]
 [ 40. 178.   6.   1.   5.   0.   5.  14.  15.   3.]
 [ 27.   3.  64.   3.   2.   2.   2.   8.  13.   4.]
 [ 32.   1.   1. 108.   6.   4.   1.   5.  44.   6.]
 [ 37.   3.   4.   7. 201.   2.   5.  15.  26.  10.]
 [ 52.   2.   0.   6.   6.  41.   0.   2.  33.  15.]
 [ 25.   9.   4.   0.   4.   1. 106.  21.   8.   4.]
 [ 23.   3.   2.   5.   3.   1.   9. 136.  17.   0.]
 [ 44.   0.   4.   4.   7.   1.   4.  11. 399.  11.]
 [ 22.   1.   1.   6.   8.   6.   3.   5.  34. 114.]]
*******************************************

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 16, Learning Rate: 0.02, Epoch: 1
Loss Value: 2.03%
Train Accuracy: 35.90%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 16, Learning Rate: 0.02, Epoch: 2
Loss Value: 1.90%
Train Accuracy: 40.71%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 16, Learning Rate: 0.02, Epoch: 3
Loss Value: 1.80%
Train Accuracy: 44.61%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 16, Learning Rate: 0.02, Epoch: 4
Loss Value: 1.71%
Train Accuracy: 48.34%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 16, Learning Rate: 0.02, Epoch: 5
Loss Value: 1.62%
Train Accuracy: 51.51%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 16, Learning Rate: 0.02, Epoch: 6
Loss Value: 1.53%
Train Accuracy: 54.49%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 16, Learning Rate: 0.02, Epoch: 7
Loss Value: 1.44%
Train Accuracy: 57.61%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 16, Learning Rate: 0.02, Epoch: 8
Loss Value: 1.35%
Train Accuracy: 60.16%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 16, Learning Rate: 0.02, Epoch: 9
Loss Value: 1.28%
Train Accuracy: 59.67%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 16, Learning Rate: 0.02, Epoch: 10
Loss Value: 1.23%
Train Accuracy: 62.81%
Accuracy: 58.90%
Confusion matrix:
[[340.   9.   5.   7.   8.   9.   2.  14.  67.  11.]
 [ 48. 177.   7.   0.   2.   3.   4.  13.  11.   2.]
 [ 25.   4.  67.   3.   2.   2.   2.   8.  11.   4.]
 [ 47.   4.   2. 100.   3.   3.   1.   4.  40.   4.]
 [ 66.   5.   5.  12. 161.   5.   5.  20.  23.   8.]
 [ 71.   1.   2.   7.   0.  27.   1.   4.  34.  10.]
 [ 43.   7.   5.   3.   3.   2.  87.  22.   5.   5.]
 [ 47.   1.   1.   5.   1.   3.   6. 118.  16.   1.]
 [ 73.   4.   3.   9.   6.   1.   3.   9. 365.  12.]
 [ 43.   2.   1.  10.   5.   3.   3.   5.  34.  94.]]
*******************************************

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 32, Learning Rate: 0.005, Epoch: 1
Loss Value: 2.08%
Train Accuracy: 31.17%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 32, Learning Rate: 0.005, Epoch: 2
Loss Value: 1.97%
Train Accuracy: 33.81%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 32, Learning Rate: 0.005, Epoch: 3
Loss Value: 1.91%
Train Accuracy: 35.99%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 32, Learning Rate: 0.005, Epoch: 4
Loss Value: 1.86%
Train Accuracy: 38.09%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 32, Learning Rate: 0.005, Epoch: 5
Loss Value: 1.81%
Train Accuracy: 40.02%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 32, Learning Rate: 0.005, Epoch: 6
Loss Value: 1.77%
Train Accuracy: 41.88%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 32, Learning Rate: 0.005, Epoch: 7
Loss Value: 1.72%
Train Accuracy: 43.86%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 32, Learning Rate: 0.005, Epoch: 8
Loss Value: 1.67%
Train Accuracy: 46.14%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 32, Learning Rate: 0.005, Epoch: 9
Loss Value: 1.63%
Train Accuracy: 48.14%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 32, Learning Rate: 0.005, Epoch: 10
Loss Value: 1.58%
Train Accuracy: 50.30%
Accuracy: 48.26%
Confusion matrix:
[[281.  17.   0.   8.  33.   8.  11.  19.  86.   8.]
 [ 40. 148.   1.   2.  16.   0.  21.   9.  26.   2.]
 [ 29.  14.  16.   4.  12.   0.   8.   6.  26.  12.]
 [ 31.   4.   2.  78.  19.   3.   2.   5.  56.   4.]
 [ 53.   9.   2.  11. 145.   0.  16.  16.  49.   7.]
 [ 62.   1.   0.   7.   6.  21.   2.   9.  41.   6.]
 [ 36.  26.   2.   1.  12.   2.  68.  19.  11.   5.]
 [ 49.  15.   0.   6.   7.   1.  22.  68.  27.   3.]
 [ 45.   7.   1.   7.  14.   3.   8.  10. 380.   8.]
 [ 43.  12.   0.  16.  21.   6.   4.   8.  43.  46.]]
*******************************************

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 32, Learning Rate: 0.01, Epoch: 1
Loss Value: 2.04%
Train Accuracy: 33.11%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 32, Learning Rate: 0.01, Epoch: 2
Loss Value: 1.91%
Train Accuracy: 36.60%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 32, Learning Rate: 0.01, Epoch: 3
Loss Value: 1.83%
Train Accuracy: 40.04%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 32, Learning Rate: 0.01, Epoch: 4
Loss Value: 1.76%
Train Accuracy: 43.22%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 32, Learning Rate: 0.01, Epoch: 5
Loss Value: 1.69%
Train Accuracy: 46.74%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 32, Learning Rate: 0.01, Epoch: 6
Loss Value: 1.62%
Train Accuracy: 50.07%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 32, Learning Rate: 0.01, Epoch: 7
Loss Value: 1.54%
Train Accuracy: 53.12%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 32, Learning Rate: 0.01, Epoch: 8
Loss Value: 1.47%
Train Accuracy: 56.09%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 32, Learning Rate: 0.01, Epoch: 9
Loss Value: 1.39%
Train Accuracy: 59.09%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 32, Learning Rate: 0.01, Epoch: 10
Loss Value: 1.31%
Train Accuracy: 62.01%
Accuracy: 57.79%
Confusion matrix:
[[315.  11.   6.  15.  22.   9.   2.  14.  71.   6.]
 [ 42. 165.   4.   3.   7.   0.  13.  11.  17.   3.]
 [ 36.   6.  40.   4.   5.   1.   4.   8.  18.   5.]
 [ 24.   5.   1. 104.   8.   4.   1.   3.  49.   5.]
 [ 43.   5.   2.  12. 180.   4.   9.  14.  33.   6.]
 [ 49.   1.   1.  12.   7.  30.   1.   5.  37.  12.]
 [ 25.  17.   4.   4.   6.   1.  97.  13.  11.   4.]
 [ 44.  10.   0.   4.   6.   1.  12.  97.  23.   1.]
 [ 42.   4.   3.  14.  10.   2.   2.   8. 389.   9.]
 [ 25.   5.   2.  15.  15.   4.   2.   7.  43.  81.]]
*******************************************

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 32, Learning Rate: 0.02, Epoch: 1
Loss Value: 2.02%
Train Accuracy: 34.92%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 32, Learning Rate: 0.02, Epoch: 2
Loss Value: 1.88%
Train Accuracy: 39.47%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 32, Learning Rate: 0.02, Epoch: 3
Loss Value: 1.78%
Train Accuracy: 44.10%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 32, Learning Rate: 0.02, Epoch: 4
Loss Value: 1.69%
Train Accuracy: 47.69%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 32, Learning Rate: 0.02, Epoch: 5
Loss Value: 1.59%
Train Accuracy: 51.43%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 32, Learning Rate: 0.02, Epoch: 6
Loss Value: 1.50%
Train Accuracy: 54.81%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 32, Learning Rate: 0.02, Epoch: 7
Loss Value: 1.40%
Train Accuracy: 58.22%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 32, Learning Rate: 0.02, Epoch: 8
Loss Value: 1.31%
Train Accuracy: 61.03%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 32, Learning Rate: 0.02, Epoch: 9
Loss Value: 1.22%
Train Accuracy: 64.06%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 32, Learning Rate: 0.02, Epoch: 10
Loss Value: 1.12%
Train Accuracy: 66.80%
Accuracy: 62.15%
Confusion matrix:
[[331.   6.   7.  17.  10.   7.   3.  11.  69.  10.]
 [ 51. 168.   5.   0.   1.   1.  12.   9.  13.   5.]
 [ 23.   3.  63.   3.   2.   0.   3.  10.  16.   4.]
 [ 37.   3.   0. 105.   5.   3.   1.   6.  41.   3.]
 [ 47.   2.   4.   9. 188.   4.   9.  10.  31.   4.]
 [ 63.   1.   0.  12.   3.  30.   0.   1.  33.  12.]
 [ 29.  10.   3.   1.   3.   2. 108.  17.   5.   4.]
 [ 27.   2.   0.   3.   3.   0.  11. 132.  19.   1.]
 [ 52.   1.   5.  10.   6.   0.   3.  16. 380.  10.]
 [ 32.   1.   4.   6.   7.   6.   3.   5.  29. 106.]]
*******************************************

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 64, Learning Rate: 0.005, Epoch: 1
Loss Value: 2.11%
Train Accuracy: 29.33%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 64, Learning Rate: 0.005, Epoch: 2
Loss Value: 2.02%
Train Accuracy: 31.42%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 64, Learning Rate: 0.005, Epoch: 3
Loss Value: 1.97%
Train Accuracy: 33.05%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 64, Learning Rate: 0.005, Epoch: 4
Loss Value: 1.94%
Train Accuracy: 34.35%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 64, Learning Rate: 0.005, Epoch: 5
Loss Value: 1.91%
Train Accuracy: 35.46%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 64, Learning Rate: 0.005, Epoch: 6
Loss Value: 1.88%
Train Accuracy: 36.52%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 64, Learning Rate: 0.005, Epoch: 7
Loss Value: 1.85%
Train Accuracy: 37.76%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 64, Learning Rate: 0.005, Epoch: 8
Loss Value: 1.83%
Train Accuracy: 38.98%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 64, Learning Rate: 0.005, Epoch: 9
Loss Value: 1.80%
Train Accuracy: 40.15%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 64, Learning Rate: 0.005, Epoch: 10
Loss Value: 1.78%
Train Accuracy: 41.26%
Accuracy: 40.62%
Confusion matrix:
[[260.  27.   0.   7.  31.   4.   7.  16. 105.   8.]
 [ 46. 129.   0.   1.  21.   0.  20.  10.  32.   3.]
 [ 35.  19.   3.   2.  15.   1.   6.   6.  34.   4.]
 [ 47.   6.   0.  44.  23.   3.   5.   5.  64.   3.]
 [ 56.  20.   0.  10. 120.   0.  12.  20.  54.  11.]
 [ 63.   1.   0.   9.   8.  16.   3.   8.  42.   4.]
 [ 38.  33.   0.   1.  17.   1.  49.  18.  21.   3.]
 [ 51.  21.   0.   6.  17.   0.  18.  60.  23.   1.]
 [ 57.  18.   0.  12.  25.   3.   8.  15. 333.   7.]
 [ 56.  14.   0.  14.  18.   3.   6.   7.  51.  26.]]
*******************************************

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 64, Learning Rate: 0.01, Epoch: 1
Loss Value: 2.08%
Train Accuracy: 31.22%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 64, Learning Rate: 0.01, Epoch: 2
Loss Value: 1.97%
Train Accuracy: 33.87%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 64, Learning Rate: 0.01, Epoch: 3
Loss Value: 1.91%
Train Accuracy: 35.96%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 64, Learning Rate: 0.01, Epoch: 4
Loss Value: 1.86%
Train Accuracy: 37.95%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 64, Learning Rate: 0.01, Epoch: 5
Loss Value: 1.81%
Train Accuracy: 39.92%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 64, Learning Rate: 0.01, Epoch: 6
Loss Value: 1.77%
Train Accuracy: 41.95%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 64, Learning Rate: 0.01, Epoch: 7
Loss Value: 1.72%
Train Accuracy: 43.95%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 64, Learning Rate: 0.01, Epoch: 8
Loss Value: 1.68%
Train Accuracy: 45.89%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 64, Learning Rate: 0.01, Epoch: 9
Loss Value: 1.63%
Train Accuracy: 48.07%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 64, Learning Rate: 0.01, Epoch: 10
Loss Value: 1.58%
Train Accuracy: 50.15%
Accuracy: 47.70%
Confusion matrix:
[[275.  17.   0.   9.  37.   5.  12.  16.  88.   6.]
 [ 42. 145.   1.   0.  15.   0.  23.  10.  26.   0.]
 [ 31.  10.  16.   3.  11.   1.  11.   5.  31.   6.]
 [ 33.   5.   1.  62.  22.   3.   3.   6.  60.   5.]
 [ 50.   9.   1.  14. 144.   0.  12.  19.  44.  10.]
 [ 58.   1.   0.  10.   7.  19.   3.   9.  41.   6.]
 [ 35.  28.   1.   2.  12.   1.  70.  16.  13.   3.]
 [ 50.  15.   1.   3.   8.   0.  21.  64.  33.   2.]
 [ 45.   5.   0.   6.  11.   4.   9.  13. 375.  10.]
 [ 39.   9.   1.  15.  21.   6.   5.   8.  40.  51.]]
*******************************************

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 64, Learning Rate: 0.02, Epoch: 1
Loss Value: 2.04%
Train Accuracy: 33.18%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 64, Learning Rate: 0.02, Epoch: 2
Loss Value: 1.92%
Train Accuracy: 36.46%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 64, Learning Rate: 0.02, Epoch: 3
Loss Value: 1.84%
Train Accuracy: 39.87%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 64, Learning Rate: 0.02, Epoch: 4
Loss Value: 1.77%
Train Accuracy: 43.02%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 64, Learning Rate: 0.02, Epoch: 5
Loss Value: 1.70%
Train Accuracy: 46.32%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 64, Learning Rate: 0.02, Epoch: 6
Loss Value: 1.63%
Train Accuracy: 49.47%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 64, Learning Rate: 0.02, Epoch: 7
Loss Value: 1.56%
Train Accuracy: 52.31%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 64, Learning Rate: 0.02, Epoch: 8
Loss Value: 1.49%
Train Accuracy: 55.41%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 64, Learning Rate: 0.02, Epoch: 9
Loss Value: 1.42%
Train Accuracy: 58.36%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 64, Learning Rate: 0.02, Epoch: 10
Loss Value: 1.35%
Train Accuracy: 61.01%
Accuracy: 56.76%
Confusion matrix:
[[306.  12.   8.  12.  23.   7.   7.  14.  68.   8.]
 [ 41. 168.   3.   0.   9.   1.  14.   8.  16.   2.]
 [ 31.   5.  43.   4.   7.   1.   6.   5.  17.   6.]
 [ 29.   4.   1.  86.  10.   5.   1.   7.  52.   5.]
 [ 43.   6.   2.   9. 177.   4.   9.  15.  34.   4.]
 [ 49.   1.   2.  10.   9.  30.   2.   6.  35.  10.]
 [ 24.  17.   4.   5.   8.   0.  99.  11.   8.   5.]
 [ 38.   9.   1.   5.   4.   2.  13.  96.  26.   3.]
 [ 46.   3.   4.  12.  14.   2.   2.  10. 374.  11.]
 [ 34.   5.   3.   9.  13.   7.   3.   5.  42.  74.]]
*******************************************

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 128, Learning Rate: 0.005, Epoch: 1
Loss Value: 2.15%
Train Accuracy: 27.41%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 128, Learning Rate: 0.005, Epoch: 2
Loss Value: 2.07%
Train Accuracy: 29.50%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 128, Learning Rate: 0.005, Epoch: 3
Loss Value: 2.03%
Train Accuracy: 30.84%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 128, Learning Rate: 0.005, Epoch: 4
Loss Value: 2.00%
Train Accuracy: 31.75%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 128, Learning Rate: 0.005, Epoch: 5
Loss Value: 1.98%
Train Accuracy: 32.62%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 128, Learning Rate: 0.005, Epoch: 6
Loss Value: 1.96%
Train Accuracy: 33.36%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 128, Learning Rate: 0.005, Epoch: 7
Loss Value: 1.94%
Train Accuracy: 33.96%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 128, Learning Rate: 0.005, Epoch: 8
Loss Value: 1.92%
Train Accuracy: 34.51%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 128, Learning Rate: 0.005, Epoch: 9
Loss Value: 1.91%
Train Accuracy: 35.08%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 128, Learning Rate: 0.005, Epoch: 10
Loss Value: 1.89%
Train Accuracy: 35.68%
Accuracy: 34.22%
Confusion matrix:
[[256.  32.   0.  10.  34.   3.   6.  15. 107.   2.]
 [ 58. 116.   0.   0.  21.   0.  13.  14.  39.   1.]
 [ 35.  26.   0.   2.  19.   0.   5.   3.  34.   1.]
 [ 72.   5.   0.  30.  22.   0.   2.   4.  64.   1.]
 [ 77.  27.   0.   8. 100.   0.   7.  25.  53.   6.]
 [ 77.   2.   0.  10.  11.   3.   1.   6.  43.   1.]
 [ 51.  37.   0.   0.  20.   0.  26.  16.  28.   3.]
 [ 66.  21.   0.   5.  19.   0.   9.  48.  28.   1.]
 [ 97.  23.   0.  13.  33.   2.   3.  13. 289.   5.]
 [ 80.  16.   0.   6.  20.   3.   2.   6.  54.   8.]]
*******************************************

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 128, Learning Rate: 0.01, Epoch: 1
Loss Value: 2.11%
Train Accuracy: 29.72%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 128, Learning Rate: 0.01, Epoch: 2
Loss Value: 2.02%
Train Accuracy: 31.58%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 128, Learning Rate: 0.01, Epoch: 3
Loss Value: 1.97%
Train Accuracy: 33.22%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 128, Learning Rate: 0.01, Epoch: 4
Loss Value: 1.93%
Train Accuracy: 34.49%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 128, Learning Rate: 0.01, Epoch: 5
Loss Value: 1.90%
Train Accuracy: 35.64%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 128, Learning Rate: 0.01, Epoch: 6
Loss Value: 1.87%
Train Accuracy: 36.64%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 128, Learning Rate: 0.01, Epoch: 7
Loss Value: 1.85%
Train Accuracy: 37.84%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 128, Learning Rate: 0.01, Epoch: 8
Loss Value: 1.82%
Train Accuracy: 39.05%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 128, Learning Rate: 0.01, Epoch: 9
Loss Value: 1.80%
Train Accuracy: 40.05%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 128, Learning Rate: 0.01, Epoch: 10
Loss Value: 1.77%
Train Accuracy: 41.19%
Accuracy: 40.16%
Confusion matrix:
[[256.  26.   0.   8.  30.   5.   7.  20. 105.   8.]
 [ 42. 130.   0.   1.  23.   0.  20.  12.  33.   1.]
 [ 35.  20.   2.   2.  16.   1.   7.   6.  30.   6.]
 [ 45.   4.   1.  46.  22.   2.   6.   4.  65.   5.]
 [ 60.  16.   1.  11. 117.   0.  15.  20.  53.  10.]
 [ 63.   1.   0.  12.   6.  11.   3.   9.  45.   4.]
 [ 39.  31.   0.   0.  15.   1.  53.  18.  19.   5.]
 [ 51.  20.   0.   6.  12.   0.  19.  61.  25.   3.]
 [ 62.  21.   0.  10.  27.   3.   6.  14. 325.  10.]
 [ 57.  15.   0.  12.  19.   3.   6.   6.  50.  27.]]
*******************************************

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 128, Learning Rate: 0.02, Epoch: 1
Loss Value: 2.07%
Train Accuracy: 31.45%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 128, Learning Rate: 0.02, Epoch: 2
Loss Value: 1.97%
Train Accuracy: 34.03%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 128, Learning Rate: 0.02, Epoch: 3
Loss Value: 1.91%
Train Accuracy: 36.02%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 128, Learning Rate: 0.02, Epoch: 4
Loss Value: 1.86%
Train Accuracy: 37.91%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 128, Learning Rate: 0.02, Epoch: 5
Loss Value: 1.81%
Train Accuracy: 39.85%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 128, Learning Rate: 0.02, Epoch: 6
Loss Value: 1.77%
Train Accuracy: 41.72%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 128, Learning Rate: 0.02, Epoch: 7
Loss Value: 1.72%
Train Accuracy: 43.48%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 128, Learning Rate: 0.02, Epoch: 8
Loss Value: 1.68%
Train Accuracy: 45.52%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 128, Learning Rate: 0.02, Epoch: 9
Loss Value: 1.63%
Train Accuracy: 47.64%

------------------------------------------------------------
Neurons: [4096, 1024, 10], Batch Size: 128, Learning Rate: 0.02, Epoch: 10
Loss Value: 1.59%
Train Accuracy: 49.56%
Accuracy: 46.48%
Confusion matrix:
[[262.  23.   0.  11.  32.   5.  11.  16.  99.   6.]
 [ 44. 136.   2.   1.  16.   0.  28.   8.  27.   0.]
 [ 32.   8.  17.   3.  12.   1.  10.   5.  29.   8.]
 [ 28.   4.   1.  68.  23.   2.   4.   4.  61.   5.]
 [ 48.   9.   1.  10. 144.   1.  13.  15.  53.   9.]
 [ 49.   1.   0.  12.   7.  19.   2.  10.  48.   6.]
 [ 32.  25.   2.   3.  16.   1.  68.  17.  13.   4.]
 [ 44.  15.   0.   5.   8.   1.  21.  72.  28.   3.]
 [ 44.   6.   0.  14.  14.   6.   9.  12. 360.  13.]
 [ 42.   6.   1.  19.  16.   7.   6.   8.  46.  44.]]
*******************************************

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 16, Learning Rate: 0.005, Epoch: 1
Loss Value: 2.18%
Train Accuracy: 24.84%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 16, Learning Rate: 0.005, Epoch: 2
Loss Value: 2.07%
Train Accuracy: 30.00%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 16, Learning Rate: 0.005, Epoch: 3
Loss Value: 1.99%
Train Accuracy: 32.85%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 16, Learning Rate: 0.005, Epoch: 4
Loss Value: 1.92%
Train Accuracy: 34.68%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 16, Learning Rate: 0.005, Epoch: 5
Loss Value: 1.87%
Train Accuracy: 36.83%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 16, Learning Rate: 0.005, Epoch: 6
Loss Value: 1.82%
Train Accuracy: 39.18%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 16, Learning Rate: 0.005, Epoch: 7
Loss Value: 1.76%
Train Accuracy: 41.53%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 16, Learning Rate: 0.005, Epoch: 8
Loss Value: 1.71%
Train Accuracy: 44.08%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 16, Learning Rate: 0.005, Epoch: 9
Loss Value: 1.65%
Train Accuracy: 46.68%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 16, Learning Rate: 0.005, Epoch: 10
Loss Value: 1.58%
Train Accuracy: 49.40%
Accuracy: 46.63%
Confusion matrix:
[[288.  25.   0.  13.  22.   5.   4.  12.  93.  10.]
 [ 45. 153.   0.   1.   7.   0.  27.   9.  23.   2.]
 [ 36.  16.   8.   2.   8.   0.  10.   5.  32.  11.]
 [ 38.   4.   1.  72.  21.   0.   2.   3.  62.   5.]
 [ 64.   7.   1.  14. 134.   0.  12.  14.  54.  10.]
 [ 67.   1.   0.  12.   6.  13.   0.   6.  45.   7.]
 [ 31.  35.   2.   4.  11.   0.  56.  23.  15.   5.]
 [ 57.  14.   2.   6.   7.   0.  21.  62.  29.   1.]
 [ 36.   2.   2.  15.   8.   3.   4.   9. 398.   8.]
 [ 46.   5.   2.  17.  24.   5.   3.   6.  60.  32.]]
*******************************************

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 16, Learning Rate: 0.01, Epoch: 1
Loss Value: 2.13%
Train Accuracy: 29.19%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 16, Learning Rate: 0.01, Epoch: 2
Loss Value: 1.98%
Train Accuracy: 33.79%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 16, Learning Rate: 0.01, Epoch: 3
Loss Value: 1.89%
Train Accuracy: 36.92%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 16, Learning Rate: 0.01, Epoch: 4
Loss Value: 1.81%
Train Accuracy: 40.28%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 16, Learning Rate: 0.01, Epoch: 5
Loss Value: 1.74%
Train Accuracy: 43.61%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 16, Learning Rate: 0.01, Epoch: 6
Loss Value: 1.66%
Train Accuracy: 47.04%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 16, Learning Rate: 0.01, Epoch: 7
Loss Value: 1.57%
Train Accuracy: 50.67%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 16, Learning Rate: 0.01, Epoch: 8
Loss Value: 1.48%
Train Accuracy: 54.26%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 16, Learning Rate: 0.01, Epoch: 9
Loss Value: 1.39%
Train Accuracy: 57.55%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 16, Learning Rate: 0.01, Epoch: 10
Loss Value: 1.28%
Train Accuracy: 60.57%
Accuracy: 55.83%
Confusion matrix:
[[311.  11.  13.  10.  13.   8.   3.  17.  80.   6.]
 [ 44. 156.  10.   0.   3.   0.  30.   8.  14.   2.]
 [ 27.   2.  51.   2.   3.   1.   4.   9.  21.   8.]
 [ 31.   3.   1. 105.   5.   4.   1.   5.  50.   3.]
 [ 55.   4.   4.   9. 155.   1.  12.  23.  38.   9.]
 [ 69.   1.   3.  12.   2.  19.   0.   2.  38.  11.]
 [ 31.  18.   6.   3.   3.   1.  79.  26.  11.   4.]
 [ 41.   5.   2.   6.   2.   0.  16. 107.  19.   1.]
 [ 48.   2.   4.  10.   7.   2.   1.   9. 395.   7.]
 [ 31.   2.   4.  18.   7.   6.   2.   6.  46.  78.]]
*******************************************

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 16, Learning Rate: 0.02, Epoch: 1
Loss Value: 2.07%
Train Accuracy: 32.84%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 16, Learning Rate: 0.02, Epoch: 2
Loss Value: 1.91%
Train Accuracy: 36.99%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 16, Learning Rate: 0.02, Epoch: 3
Loss Value: 1.81%
Train Accuracy: 40.80%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 16, Learning Rate: 0.02, Epoch: 4
Loss Value: 1.72%
Train Accuracy: 44.58%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 16, Learning Rate: 0.02, Epoch: 5
Loss Value: 1.63%
Train Accuracy: 47.98%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 16, Learning Rate: 0.02, Epoch: 6
Loss Value: 1.53%
Train Accuracy: 51.73%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 16, Learning Rate: 0.02, Epoch: 7
Loss Value: 1.42%
Train Accuracy: 55.65%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 16, Learning Rate: 0.02, Epoch: 8
Loss Value: 1.30%
Train Accuracy: 58.88%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 16, Learning Rate: 0.02, Epoch: 9
Loss Value: 1.17%
Train Accuracy: 60.80%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 16, Learning Rate: 0.02, Epoch: 10
Loss Value: 1.04%
Train Accuracy: 63.04%
Accuracy: 59.59%
Confusion matrix:
[[345.   6.  13.  11.   9.   4.   0.  14.  62.   8.]
 [ 38. 167.  10.   2.   1.   0.  18.  11.  18.   2.]
 [ 21.   0.  64.   3.   2.   2.   1.  16.  14.   5.]
 [ 28.   1.   2. 128.   2.   3.   1.   5.  33.   5.]
 [ 58.   4.   8.  12. 144.   2.  10.  30.  32.  10.]
 [ 74.   0.   3.   8.   1.  24.   0.   5.  34.   8.]
 [ 27.   6.   6.   4.   3.   1.  88.  34.   9.   4.]
 [ 34.   2.   3.   6.   0.   2.  10. 127.  14.   1.]
 [ 48.   2.   5.  23.   2.   2.   2.  16. 376.   9.]
 [ 28.   2.   4.  17.   6.   3.   2.   5.  42.  91.]]
*******************************************

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 32, Learning Rate: 0.005, Epoch: 1
Loss Value: 2.21%
Train Accuracy: 21.35%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 32, Learning Rate: 0.005, Epoch: 2
Loss Value: 2.14%
Train Accuracy: 25.04%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 32, Learning Rate: 0.005, Epoch: 3
Loss Value: 2.08%
Train Accuracy: 27.64%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 32, Learning Rate: 0.005, Epoch: 4
Loss Value: 2.03%
Train Accuracy: 30.42%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 32, Learning Rate: 0.005, Epoch: 5
Loss Value: 1.99%
Train Accuracy: 32.23%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 32, Learning Rate: 0.005, Epoch: 6
Loss Value: 1.95%
Train Accuracy: 33.49%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 32, Learning Rate: 0.005, Epoch: 7
Loss Value: 1.92%
Train Accuracy: 34.43%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 32, Learning Rate: 0.005, Epoch: 8
Loss Value: 1.89%
Train Accuracy: 35.44%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 32, Learning Rate: 0.005, Epoch: 9
Loss Value: 1.86%
Train Accuracy: 36.60%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 32, Learning Rate: 0.005, Epoch: 10
Loss Value: 1.82%
Train Accuracy: 37.99%
Accuracy: 36.96%
Confusion matrix:
[[233.  26.   1.   9.  30.   6.   5.  22. 137.   2.]
 [ 44. 132.   0.   0.  22.   0.  20.  16.  31.   0.]
 [ 35.  25.   0.   2.  15.   0.   6.   4.  39.   1.]
 [ 39.   6.   0.  43.  27.   2.   2.   5.  79.   1.]
 [ 68.  26.   0.   7. 104.   0.   9.  25.  68.   1.]
 [ 64.   0.   0.  11.  10.   6.   1.  10.  53.   0.]
 [ 35.  42.   0.   0.  30.   0.  28.  23.  23.   1.]
 [ 56.  24.   0.   2.  20.   0.   9.  52.  34.   1.]
 [ 50.  15.   0.  13.  33.   1.   0.  13. 355.   3.]
 [ 69.  14.   0.   9.  27.   1.   1.   6.  67.   5.]]
*******************************************

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 32, Learning Rate: 0.01, Epoch: 1
Loss Value: 2.18%
Train Accuracy: 24.81%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 32, Learning Rate: 0.01, Epoch: 2
Loss Value: 2.07%
Train Accuracy: 29.98%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 32, Learning Rate: 0.01, Epoch: 3
Loss Value: 1.99%
Train Accuracy: 32.80%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 32, Learning Rate: 0.01, Epoch: 4
Loss Value: 1.92%
Train Accuracy: 34.53%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 32, Learning Rate: 0.01, Epoch: 5
Loss Value: 1.87%
Train Accuracy: 36.62%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 32, Learning Rate: 0.01, Epoch: 6
Loss Value: 1.82%
Train Accuracy: 39.04%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 32, Learning Rate: 0.01, Epoch: 7
Loss Value: 1.76%
Train Accuracy: 41.60%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 32, Learning Rate: 0.01, Epoch: 8
Loss Value: 1.71%
Train Accuracy: 44.05%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 32, Learning Rate: 0.01, Epoch: 9
Loss Value: 1.65%
Train Accuracy: 46.91%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 32, Learning Rate: 0.01, Epoch: 10
Loss Value: 1.59%
Train Accuracy: 49.53%
Accuracy: 46.72%
Confusion matrix:
[[286.  22.   1.  15.  29.   7.   4.  16.  82.   9.]
 [ 42. 150.   2.   0.  11.   0.  28.  10.  21.   1.]
 [ 34.  16.  11.   4.   7.   0.  12.   4.  31.   8.]
 [ 36.   3.   0.  67.  24.   0.   0.   3.  63.   8.]
 [ 65.   7.   1.  12. 134.   0.   9.  20.  50.  10.]
 [ 73.   1.   0.  11.   4.  12.   0.   5.  42.   7.]
 [ 38.  32.   1.   3.  13.   0.  59.  20.  12.   4.]
 [ 47.  11.   1.   4.   8.   0.  27.  69.  30.   1.]
 [ 43.   2.   1.  11.  13.   0.   2.  11. 393.   7.]
 [ 52.   5.   3.  21.  19.   5.   1.   8.  55.  30.]]
*******************************************

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 32, Learning Rate: 0.02, Epoch: 1
Loss Value: 2.13%
Train Accuracy: 29.34%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 32, Learning Rate: 0.02, Epoch: 2
Loss Value: 1.98%
Train Accuracy: 33.72%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 32, Learning Rate: 0.02, Epoch: 3
Loss Value: 1.89%
Train Accuracy: 36.76%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 32, Learning Rate: 0.02, Epoch: 4
Loss Value: 1.81%
Train Accuracy: 40.05%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 32, Learning Rate: 0.02, Epoch: 5
Loss Value: 1.74%
Train Accuracy: 43.38%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 32, Learning Rate: 0.02, Epoch: 6
Loss Value: 1.66%
Train Accuracy: 46.76%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 32, Learning Rate: 0.02, Epoch: 7
Loss Value: 1.58%
Train Accuracy: 50.34%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 32, Learning Rate: 0.02, Epoch: 8
Loss Value: 1.50%
Train Accuracy: 53.38%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 32, Learning Rate: 0.02, Epoch: 9
Loss Value: 1.40%
Train Accuracy: 56.81%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 32, Learning Rate: 0.02, Epoch: 10
Loss Value: 1.31%
Train Accuracy: 59.73%
Accuracy: 56.13%
Confusion matrix:
[[326.   8.   9.  13.  12.   7.   1.  14.  76.   5.]
 [ 51. 165.   7.   0.   1.   0.  20.   6.  15.   0.]
 [ 34.   4.  46.   3.   2.   1.   3.   8.  20.   6.]
 [ 37.   2.   0.  96.   5.   3.   0.   5.  49.   7.]
 [ 63.   3.   4.  10. 151.   1.  10.  19.  38.   9.]
 [ 77.   0.   0.  10.   3.  18.   1.   2.  34.  10.]
 [ 36.  18.   5.   2.   3.   0.  80.  23.  10.   5.]
 [ 49.   4.   4.   5.   0.   0.  18.  98.  19.   1.]
 [ 47.   0.   4.   5.   4.   3.   1.   7. 401.  11.]
 [ 40.   3.   3.  15.   4.   5.   3.   5.  47.  74.]]
*******************************************

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 64, Learning Rate: 0.005, Epoch: 1
Loss Value: 2.25%
Train Accuracy: 21.41%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 64, Learning Rate: 0.005, Epoch: 2
Loss Value: 2.18%
Train Accuracy: 22.07%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 64, Learning Rate: 0.005, Epoch: 3
Loss Value: 2.15%
Train Accuracy: 23.37%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 64, Learning Rate: 0.005, Epoch: 4
Loss Value: 2.12%
Train Accuracy: 25.54%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 64, Learning Rate: 0.005, Epoch: 5
Loss Value: 2.09%
Train Accuracy: 26.81%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 64, Learning Rate: 0.005, Epoch: 6
Loss Value: 2.07%
Train Accuracy: 27.87%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 64, Learning Rate: 0.005, Epoch: 7
Loss Value: 2.04%
Train Accuracy: 29.19%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 64, Learning Rate: 0.005, Epoch: 8
Loss Value: 2.02%
Train Accuracy: 30.43%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 64, Learning Rate: 0.005, Epoch: 9
Loss Value: 2.00%
Train Accuracy: 31.56%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 64, Learning Rate: 0.005, Epoch: 10
Loss Value: 1.98%
Train Accuracy: 32.47%
Accuracy: 31.05%
Confusion matrix:
[[242.  30.   0.   8.  25.   0.   4.  13. 143.   0.]
 [ 66.  96.   0.   0.  23.   0.  14.  17.  46.   0.]
 [ 33.  27.   0.   1.  23.   0.   0.   5.  36.   0.]
 [ 75.   6.   0.  15.  18.   0.   1.   4.  81.   0.]
 [ 97.  37.   0.   4.  77.   0.   5.  20.  63.   0.]
 [ 86.   1.   0.   7.  13.   0.   2.   4.  41.   0.]
 [ 60.  39.   0.   0.  25.   0.  11.  17.  29.   0.]
 [ 77.  19.   0.   0.  20.   0.   9.  42.  30.   0.]
 [ 97.  22.   0.   7.  29.   0.   1.  10. 312.   0.]
 [ 81.  15.   0.   2.  20.   0.   2.   7.  68.   0.]]
*******************************************

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 64, Learning Rate: 0.01, Epoch: 1
Loss Value: 2.21%
Train Accuracy: 21.31%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 64, Learning Rate: 0.01, Epoch: 2
Loss Value: 2.14%
Train Accuracy: 25.10%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 64, Learning Rate: 0.01, Epoch: 3
Loss Value: 2.09%
Train Accuracy: 27.75%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 64, Learning Rate: 0.01, Epoch: 4
Loss Value: 2.04%
Train Accuracy: 30.13%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 64, Learning Rate: 0.01, Epoch: 5
Loss Value: 2.00%
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Train Accuracy: 32.45%
Accuracy: 31.17%
Confusion matrix:
[[253.  29.   0.   5.  24.   0.   4.  14. 136.   0.]
 [ 66.  94.   0.   0.  23.   0.  14.  19.  46.   0.]
 [ 37.  26.   0.   1.  24.   0.   0.   3.  34.   0.]
 [ 76.   5.   0.  14.  20.   0.   1.   4.  80.   0.]
 [ 99.  36.   0.   2.  77.   0.   4.  18.  67.   0.]
 [ 87.   3.   0.   7.  11.   0.   2.   4.  40.   0.]
 [ 60.  40.   0.   0.  27.   0.  10.  17.  27.   0.]
 [ 79.  18.   0.   0.  22.   0.   8.  41.  29.   0.]
 [ 90.  24.   0.   8.  35.   0.   1.  11. 309.   0.]
 [ 81.  13.   0.   2.  26.   0.   1.   6.  66.   0.]]
*******************************************

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 128, Learning Rate: 0.02, Epoch: 1
Loss Value: 2.22%
Train Accuracy: 21.43%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 128, Learning Rate: 0.02, Epoch: 2
Loss Value: 2.14%
Train Accuracy: 25.56%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 128, Learning Rate: 0.02, Epoch: 3
Loss Value: 2.09%
Train Accuracy: 27.74%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 128, Learning Rate: 0.02, Epoch: 4
Loss Value: 2.04%
Train Accuracy: 30.38%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 128, Learning Rate: 0.02, Epoch: 5
Loss Value: 2.00%
Train Accuracy: 31.76%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 128, Learning Rate: 0.02, Epoch: 6
Loss Value: 1.96%
Train Accuracy: 33.18%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 128, Learning Rate: 0.02, Epoch: 7
Loss Value: 1.93%
Train Accuracy: 34.10%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 128, Learning Rate: 0.02, Epoch: 8
Loss Value: 1.90%
Train Accuracy: 34.97%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 128, Learning Rate: 0.02, Epoch: 9
Loss Value: 1.87%
Train Accuracy: 36.17%

------------------------------------------------------------
Neurons: [4096, 1024, 256, 10], Batch Size: 128, Learning Rate: 0.02, Epoch: 10
Loss Value: 1.84%
Train Accuracy: 37.62%
Accuracy: 36.88%
Confusion matrix:
[[246.  22.   1.   9.  32.   3.   4.  18. 127.   3.]
 [ 46. 126.   1.   1.  20.   0.  17.  16.  35.   0.]
 [ 30.  25.   0.   1.  19.   0.   6.   4.  40.   0.]
 [ 43.   5.   0.  35.  26.   2.   2.   5.  82.   0.]
 [ 76.  22.   0.   5. 104.   0.   5.  25.  65.   1.]
 [ 70.   1.   0.  10.   9.   4.   1.   9.  50.   0.]
 [ 39.  45.   0.   1.  23.   0.  29.  20.  23.   1.]
 [ 57.  25.   0.   0.  21.   0.  10.  50.  34.   0.]
 [ 57.  16.   0.  13.  27.   0.   3.  13. 346.   3.]
 [ 65.  16.   0.  10.  23.   2.   3.   6.  66.   4.]]
*******************************************
